from pykinect2 import PyKinectV2
from pykinect2.PyKinectV2 import *
from pykinect2 import PyKinectRuntime
from scipy import ndimage
from skimage.morphology import skeletonize,medial_axis
from sknn.mlp import Classifier, Layer
from os import system as cmd
from sknn.mlp import Classifier, Layer
import pickle
import numpy as np
import cv2
import math

class HandGestureObjectClass(object):
    def __init__(self):
        
        # Kinect runtime object, we want only color and body frames 
        self._kinect = PyKinectRuntime.PyKinectRuntime(PyKinectV2.FrameSourceTypes_Depth | PyKinectV2.FrameSourceTypes_Body)

        # here we will store skeleton data 
        self._bodies = None    

    
    def get_hand_coordinates(self, joint_points):

        right_x=int(joint_points[PyKinectV2.JointType_HandRight].x)
        right_y=int(joint_points[PyKinectV2.JointType_HandRight].y)
        left_x=int(joint_points[PyKinectV2.JointType_HandLeft].x)
        left_y=int(joint_points[PyKinectV2.JointType_HandLeft].y)
        right_x = right_x if right_x < 424 else 423
        right_y = right_y if right_y < 512 else 511
        left_x = left_x if left_x < 424 else 423
        left_y = left_y if left_y < 512 else 511

        right_hand = [right_x,right_y]
        left_hand = [left_x,left_y]
        return [right_hand,left_hand]
    def get_shoulder_coordinates(self,joint_points):
        right_sho_x=int(joint_points[PyKinectV2.JointType_ShoulderRight].x)
        right_sho_y=int(joint_points[PyKinectV2.JointType_ShoulderRight].y)
        left_sho_x=int(joint_points[PyKinectV2.JointType_ShoulderLeft].x)
        left_sho_y=int(joint_points[PyKinectV2.JointType_ShoulderLeft].y)
        right_sho_x = right_sho_x if right_sho_x < 424 else 423
        right_sho_y = right_sho_y if right_sho_y < 512 else 511
        left_sho_x = left_sho_x if left_sho_x < 424 else 423
        left_sho_y = left_sho_y if left_sho_y < 512 else 511
        right_sho = [right_sho_x,right_sho_y]
        left_sho = [left_sho_x,left_sho_y]
        return [right_sho,left_sho]
    def get_wrist_coordinates(self, joint_points):

        right_x=int(joint_points[PyKinectV2.JointType_WristRight].x)
        right_y=int(joint_points[PyKinectV2.JointType_WristRight].y)
        left_x=int(joint_points[PyKinectV2.JointType_WristLeft].x)
        left_y=int(joint_points[PyKinectV2.JointType_WristLeft].y)
       
        right_x = right_x if right_x < 424 else 423
        right_y = right_y if right_y < 512 else 511
        left_x = left_x if left_x < 424 else 423
        left_y = left_y if left_y < 512 else 511

        right_wrist = [right_x,right_y]
        left_wrist = [left_x,left_y]
        return [right_wrist,left_wrist]

    def neighbourhood(self, array, radius, seed):
        neighbour = np.array(array)
        neighbour *= 0
        print '::'+str(seed)+''
        temp = np.array(array[seed[1]-radius:seed[1]+radius, seed[0]-radius:seed[0]+radius], dtype = np.uint16)
        # cv2.imshow('hand',temp)
        # ret,temp = cv2.threshold(temp,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)
        print str(seed[1]-radius)+':'+str(seed[1]+radius)+','+str(seed[0]-radius)+':'+str(seed[0]+radius)
        print np.shape(temp)

        return temp,[(seed[1]-radius),(seed[1]+radius)],[(seed[0]-radius),(seed[0]+radius)]

    def merge(self, array_big, array_small, coord1,coord0 ):
        # [a,b] = np.shape(array_small)
        # print str(a)+'sudfs'+str(b)
        # print str(seed)+'::'
        if array_big != None:
            array_big[coord1[0]:coord1[1], coord0[0]:coord0[1]] = array_small
        return array_big
    
    def max_hist_depth(self, frame):    
        #print 'FRAME_MAX = ' + str(frame.max())
        binaries = int(frame.max())
        if binaries <= 0:
            return 0
        histogram, bins = np.histogram(frame, bins = binaries)
        histogram = histogram.tolist(); bins = bins.tolist(); 
        histogram[0 : 1] = [0, 0]
        max_hist = bins[histogram.index( max(histogram) )]
        return max_hist
    
    def max_area_contour(self, contours):
        max_area = 0
        ci = 0

        for i in range(len(contours)):
            cnt=contours[i]
            area = cv2.contourArea(cnt)
            if(area>max_area):
                max_area=area
                ci=i

        # print '\n'+str(ci)+str(len(contours))
        return contours[ci],max_area
   

    def min_depth(self, array):
        return np.amin(array)

    def get_radius(self, joint_points):

        radius_left =int(2* math.sqrt((int(joint_points[PyKinectV2.JointType_HandLeft].x)-int(joint_points[PyKinectV2.JointType_HandTipLeft].x))**2+(int(joint_points[PyKinectV2.JointType_HandLeft].y)-int(joint_points[PyKinectV2.JointType_HandTipLeft].y))**2))+1
        radius_right =int(2* math.sqrt((int(joint_points[PyKinectV2.JointType_HandRight].x)-int(joint_points[PyKinectV2.JointType_HandTipRight].x))**2+(int(joint_points[PyKinectV2.JointType_HandRight].y)-int(joint_points[PyKinectV2.JointType_HandTipRight].y))**2))+1
        # print radiuqs_right

        return max(radius_right,radius_left)

    def plot_contours(self,hand_filtered,binary):


        img1,hand_contours, hierarchy1 = cv2.findContours(binary ,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)
        if len(hand_contours) == 0:
            # print 'None'
            return 0,0,0,6,300
        else:
            # print 'not None'
            cnt, area = self.max_area_contour(hand_contours)
            hull = cv2.convexHull(cnt,returnPoints = False)

            kernel = np.ones((10,10),np.uint8)
            erosion = cv2.erode(binary,kernel,iterations = 1)
            dilation = cv2.dilate(erosion,kernel,iterations = 1)
            palm = np.array(dilation)
                    
            img1, palm_contours, hierarchy1 = cv2.findContours(palm, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
            
            if len(palm_contours) == 0:
                match = 300
            else:
                cnt_palm, area_palm = self.max_area_contour(palm_contours)  
                match = abs(area - area_palm)
                match = int(match)
                # print "::MATCH\t"+str(match)

            defects = cv2.convexityDefects(cnt,hull)
            drawing = np.zeros(hand_filtered.shape,np.uint8)
            drawing = cv2.cvtColor(drawing,cv2.COLOR_GRAY2RGB)
            fingers = 0

            if defects != None: 
                for i in range(defects.shape[0]):
                    k=1
                    s,e,f,d = defects[i,0]
                    start = tuple(cnt[s][0])
                    end = tuple(cnt[e][0])
                    far = tuple(cnt[f][0])
                    if d>1000:
                        cv2.circle(drawing,far,5,[0,0,255],-1)
                        cv2.circle(drawing,end,5,[0,255,255],-1)
                        fingers =fingers + 1
                    #rect = cv2.minAreaRect(cnt)
                    #angle=rect[2]
                    #width,height=rect[1]
                    #box = cv2.boxPoints(rect)
                    #box = np.int0(box)
                    #area = cv2.contourArea(cnt)
                    #print area
                    drawing = cv2.drawContours(drawing,[cnt],-1,150,1)
                return drawing,far,end,fingers,match


    def run(self):
        
        #Initialize variables

        print_frame = None
        depth_frame = np.zeros((424,512), dtype = np.uint16)
        initial = np.zeros((424,512), dtype = np.uint16)
        painting=np.zeros(424*512)
        painting =painting.reshape(424,512)
        painting = np.array(painting/255, dtype = np.uint8)
        painting = cv2.cvtColor(painting,cv2.COLOR_GRAY2RGB)
        
#ANNNNNN
        ann_file = open('nn.pkl','rb')
        nn = pickle.load(ann_file)

        while (True):
            #Inits per cycle
            cmd('cls')                  #Clears the screen
            body_present = 0
            painting_cursor=np.zeros(424*512)
            painting_cursor =painting_cursor.reshape(424,512)
            painting_cursor = np.array(painting_cursor/255, dtype = np.uint8)
            ret, painting_cursor = cv2.threshold(painting_cursor,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
            
            painting_cursor = cv2.cvtColor(painting_cursor,cv2.COLOR_GRAY2RGB) 
                    
            #Get depth frames
            if self._kinect.has_new_depth_frame():
                frame = self._kinect.get_last_depth_frame()
                frame = np.array(frame*9, dtype= np.uint16)
                frame = frame.reshape(424,512)
                depth_frame = np.array(frame)
                cv2.imshow('raw',depth_frame)
                frame = None
            if self._kinect.has_new_color_frame():
                print 'ok'
                #color_frame=self._kinect.get_last_color_frame()
                #color_frame=color_frame(1920,1080,3)
                #cv2.imshow('color_frame',color_frame)
            #Check if body frames are ready and take the latest one
            if self._kinect.has_new_body_frame():
                self._bodies = self._kinect.get_last_body_frame()

            #Extract Body
            if self._bodies is not None:                
                for i in range(0, self._kinect.max_body_count):
                    body = self._bodies.bodies[i]
                    if not body.is_tracked:
                        print '::NO Body tracked'             
                        continue 
                        print ':: after_continue'
                    else:
                        #print '::Body tracked'
                        body_present = 1
                        break

            if body_present == 1:
                joints = body.joints 
                #print '::Body tracked'
                # convert joint coordinates to depth space 
                joint_points = self._kinect.body_joints_to_depth_space(joints)
                [right_hand, left_hand] = self.get_hand_coordinates(joint_points)
                [right_wrist, left_wrist] = self.get_wrist_coordinates(joint_points)
                [right_sho,left_sho]=self.get_shoulder_coordinates(joint_points)
                # d = 40
                 
                d = self.get_radius(joint_points)
                print_frame = np.zeros(np.shape(depth_frame))
# HAND FILTERING               
                if depth_frame != None: 
                    neighbour = np.array(depth_frame)
                    neighbour *= 0

                    right_hand_filtered,right_coord1,right_coord0 = self.neighbourhood(depth_frame,d,right_hand)
                    left_hand_filtered,left_coord1,left_coord0 = self.neighbourhood(depth_frame,d,left_hand)
                    
                    #cv2.imshow('depth',depth_frame)

                    if right_hand_filtered != None:
                        right_hand_depth = right_hand_filtered[d,d] 
                        right_hand_filtered[right_hand_filtered > right_hand_depth + 1200] = 0
                        # right_hand_filtered[right_hand_filtered < right_hand_depth - 1200] = 0

                        right_hand_filtered_depth_frame = self.merge(neighbour, right_hand_filtered,right_coord1,right_coord0)                     
                        neighbour = right_hand_filtered_depth_frame

                    if left_hand_filtered != None:
                        left_hand_depth = left_hand_filtered[d,d] 
                        left_hand_filtered[left_hand_filtered > left_hand_depth + 1200] = 0
                        # left_hand_filtered[left_hand_filtered < left_hand_depth - 1200] = 0
                        
                        left_hand_filtered_depth_frame = self.merge(neighbour, left_hand_filtered,left_coord1,left_coord0)                         
                        # ret,left_hand_filtered_depth_frame = cv2.threshold(left_hand_filtered_depth_frame,0,255,cv2.THRESH_OTSU)
                                       
                    hand_filtered = left_hand_filtered_depth_frame
                    hand_filtered_8 = np.array(hand_filtered/255, dtype = np.uint8)
                    # hand_filtered += right_hand_filtered_depth_frame

                    cv2.imshow('final',hand_filtered)
                    cv2.circle(hand_filtered_8,tuple(right_wrist),5,[150,50,255],-1)
                    # cv2.imshow('8-bit', hand_filtered_8)


                    right = np.array(right_hand_filtered/255, dtype = np.uint8)
                    ret , right_binary = cv2.threshold(right,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)

                    left = np.array(left_hand_filtered/255, dtype = np.uint8)
                    ret , left_binary = cv2.threshold(left,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)

                    #cv2.imshow("Right_erode", right_palm)
                    
# SKELETONIZATION
                    # ret, right11 = cv2.threshold(right,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                    # skel = skeletonize(right11).astype(np.uint8)
                    # skel = skel*255
                    # right[skel > 1] = 255
                    # cv2.imshow('skeleton',right)

                    
# FINGER DETECTION
                    right_drawing,right_far,right_end,right_fingers,right_match = self.plot_contours(right_hand_filtered,right_binary)
                    left_drawing,left_far,left_end,left_fingers,left_match = self.plot_contours(left_hand_filtered,left_binary)

                    right_features = [float(right_fingers)/7,float(right_match)/400]
                    left_features = [float(left_fingers)/7,float(left_match)/400]

                    # file.write(str(features)+"\n")                    
                    # print right_wrist
                    right_a = np.asarray([right_features])
                    right_op = nn.predict(right_a)
                    # print "::O"+str(op[0][0])

                    left_a = np.asarray([left_features])
                    left_op = nn.predict(left_a)

                    if right_op[0][0]==0 and left_op[0][0]==0:
                        print "GESTURE:right_closed left_closed"
                    elif right_op[0][0]==0 and left_op[0][0]==1:
                        print "GESTURE:right_closed left_open"
                    elif right_op[0][0]==1 and left_op[0][0]==0:
                        print "GESTURE:right_open left_closed"
                    else :
                        print "GESTURE:right_open left_open"
                    
                    # right_sho_depth=depth_frame[right_sho[1],right_sho[0]]
                    # if (right_sho_depth<1 | right_hand_depth<1):
                    #     #print '1'
                    #     temp=5
                    # else:
                    #     #print '2'
                    #     temp=(right_sho_depth-right_hand_depth)/500
                   
# AREA DETECTION
                    
                
                cv2.imshow
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                file.close()

        # Close our Kinect sensor, close the window and quit.
        self._kinect.close()



HandGestureObject = HandGestureObjectClass();
HandGestureObject.run();